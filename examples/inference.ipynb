{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import dataclasses\n",
                "\n",
                "import jax\n",
                "\n",
                "from openpi.models import model as _model\n",
                "from openpi.policies import droid_policy\n",
                "from openpi.policies import policy_config as _policy_config\n",
                "from openpi.shared import download\n",
                "from openpi.training import config as _config\n",
                "from openpi.training import data_loader as _data_loader"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Policy inference\n",
                "\n",
                "The following example shows how to create a policy from a checkpoint and run inference on a dummy example."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "801ec1aab2734e27ba1a42b2e7ea4f87",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0.00/10.1G [00:00<?, ?iB/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7443018bcfcf42618b7c9e0af00f751f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0.00/4.07M [00:00<?, ?iB/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8f56bf6b9c14485682675faa80cb582d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "processor_config.json:   0%|          | 0.00/253 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "425e9e4d07bd46f8bfa3bb68cfa4adf9",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "processing_action_tokenizer.py: 0.00B [00:00, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "A new version of the following files was downloaded from https://huggingface.co/physical-intelligence/fast:\n",
                        "- processing_action_tokenizer.py\n",
                        ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e143bc8bf74e486b89571c19c18bdbfa",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "tokenizer_config.json:   0%|          | 0.00/322 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "818ab37625414e19bec9141ac5f0e9b3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "tokenizer.json: 0.00B [00:00, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8be1f1b355bf4082b3419dea4e21bb7a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "special_tokens_map.json:   0%|          | 0.00/3.00 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-12-12 08:42:16.778621: E external/xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=4,k3=0} for conv %cudnn-conv-bias-activation.9 = (f32[1,16,16,1152]{3,2,1,0}, u8[0]{0}) custom-call(%bitcast.8634, %bitcast.8871, %bitcast.8873), window={size=14x14 stride=14x14}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_name=\"jit(fun)/jit(main)/_Module/embedding/conv_general_dilated\" source_file=\"/home/i2rt/openpi/.venv/lib/python3.11/site-packages/flax/linen/linear.py\" source_line=658}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
                        "2025-12-12 08:42:18.651495: E external/xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.872897213s\n",
                        "Trying algorithm eng11{k2=4,k3=0} for conv %cudnn-conv-bias-activation.9 = (f32[1,16,16,1152]{3,2,1,0}, u8[0]{0}) custom-call(%bitcast.8634, %bitcast.8871, %bitcast.8873), window={size=14x14 stride=14x14}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_name=\"jit(fun)/jit(main)/_Module/embedding/conv_general_dilated\" source_file=\"/home/i2rt/openpi/.venv/lib/python3.11/site-packages/flax/linen/linear.py\" source_line=658}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
                        "2025-12-12 08:42:19.651598: E external/xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng35{k2=4,k3=0} for conv %cudnn-conv-bias-activation.9 = (f32[1,16,16,1152]{3,2,1,0}, u8[0]{0}) custom-call(%bitcast.8634, %bitcast.8871, %bitcast.8873), window={size=14x14 stride=14x14}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_name=\"jit(fun)/jit(main)/_Module/embedding/conv_general_dilated\" source_file=\"/home/i2rt/openpi/.venv/lib/python3.11/site-packages/flax/linen/linear.py\" source_line=658}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
                        "2025-12-12 08:42:26.389586: E external/xla/xla/service/slow_operation_alarm.cc:140] The operation took 7.738043211s\n",
                        "Trying algorithm eng35{k2=4,k3=0} for conv %cudnn-conv-bias-activation.9 = (f32[1,16,16,1152]{3,2,1,0}, u8[0]{0}) custom-call(%bitcast.8634, %bitcast.8871, %bitcast.8873), window={size=14x14 stride=14x14}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_name=\"jit(fun)/jit(main)/_Module/embedding/conv_general_dilated\" source_file=\"/home/i2rt/openpi/.venv/lib/python3.11/site-packages/flax/linen/linear.py\" source_line=658}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
                        "2025-12-12 08:42:27.392398: E external/xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv-bias-activation.9 = (f32[1,16,16,1152]{3,2,1,0}, u8[0]{0}) custom-call(%bitcast.8634, %bitcast.8871, %bitcast.8873), window={size=14x14 stride=14x14}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_name=\"jit(fun)/jit(main)/_Module/embedding/conv_general_dilated\" source_file=\"/home/i2rt/openpi/.venv/lib/python3.11/site-packages/flax/linen/linear.py\" source_line=658}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
                        "2025-12-12 08:42:29.857647: E external/xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.465315293s\n",
                        "Trying algorithm eng0{} for conv %cudnn-conv-bias-activation.9 = (f32[1,16,16,1152]{3,2,1,0}, u8[0]{0}) custom-call(%bitcast.8634, %bitcast.8871, %bitcast.8873), window={size=14x14 stride=14x14}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_name=\"jit(fun)/jit(main)/_Module/embedding/conv_general_dilated\" source_file=\"/home/i2rt/openpi/.venv/lib/python3.11/site-packages/flax/linen/linear.py\" source_line=658}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Actions shape: (10, 8)\n"
                    ]
                }
            ],
            "source": [
                "config = _config.get_config(\"pi0_fast_droid\")\n",
                "checkpoint_dir = download.maybe_download(\"gs://openpi-assets/checkpoints/pi0_fast_droid\")\n",
                "\n",
                "# Create a trained policy.\n",
                "policy = _policy_config.create_trained_policy(config, checkpoint_dir)\n",
                "\n",
                "# Run inference on a dummy example. This example corresponds to observations produced by the DROID runtime.\n",
                "example = droid_policy.make_droid_example()\n",
                "result = policy.infer(example)\n",
                "\n",
                "# Delete the policy to free up memory.\n",
                "del policy\n",
                "\n",
                "print(\"Actions shape:\", result[\"actions\"].shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Working with a live model\n",
                "\n",
                "\n",
                "The following example shows how to create a live model from a checkpoint and compute training loss. First, we are going to demonstrate how to do it with fake data.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config = _config.get_config(\"pi0_aloha_sim\")\n",
                "\n",
                "checkpoint_dir = download.maybe_download(\"gs://openpi-assets/checkpoints/pi0_aloha_sim\")\n",
                "key = jax.random.key(0)\n",
                "\n",
                "# Create a model from the checkpoint.\n",
                "model = config.model.load(_model.restore_params(checkpoint_dir / \"params\"))\n",
                "\n",
                "# We can create fake observations and actions to test the model.\n",
                "obs, act = config.model.fake_obs(), config.model.fake_act()\n",
                "\n",
                "# Sample actions from the model.\n",
                "loss = model.compute_loss(key, obs, act)\n",
                "print(\"Loss shape:\", loss.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we are going to create a data loader and use a real batch of training data to compute the loss."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reduce the batch size to reduce memory usage.\n",
                "config = dataclasses.replace(config, batch_size=2)\n",
                "\n",
                "# Load a single batch of data. This is the same data that will be used during training.\n",
                "# NOTE: In order to make this example self-contained, we are skipping the normalization step\n",
                "# since it requires the normalization statistics to be generated using `compute_norm_stats`.\n",
                "loader = _data_loader.create_data_loader(config, num_batches=1, skip_norm_stats=True)\n",
                "obs, act = next(iter(loader))\n",
                "\n",
                "# Sample actions from the model.\n",
                "loss = model.compute_loss(key, obs, act)\n",
                "\n",
                "# Delete the model to free up memory.\n",
                "del model\n",
                "\n",
                "print(\"Loss shape:\", loss.shape)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
